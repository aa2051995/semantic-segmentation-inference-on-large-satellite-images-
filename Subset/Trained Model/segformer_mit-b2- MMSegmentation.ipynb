{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAE_h7XhPT7d",
    "outputId": "d27de8a1-5a0a-447e-9483-dbb16cf8a742"
   },
   "outputs": [],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMSegmentation installation\n",
    "import mmseg\n",
    "print(mmseg.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!unzip Data_Segformer.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "WnGZfribFHCx",
    "outputId": "4274d080-4554-4d89-8036-674843853437",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "import mmcv\n",
    "from mmseg.core.evaluation import get_palette\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os.path as osp\n",
    "import torch.distributed as dist\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmcv.runner import (HOOKS, DistSamplerSeedHook, EpochBasedRunner,\n",
    "                         build_runner, get_dist_info)\n",
    "import importlib_metadata\n",
    "from mmcv.utils import build_from_cfg\n",
    "from mmseg import digit_version\n",
    "from mmseg.core import DistEvalHook, EvalHook, build_optimizer\n",
    "from mmseg.datasets import build_dataloader, build_dataset\n",
    "from mmseg.utils import find_latest_checkpoint, get_root_logger\n",
    "\n",
    "data_root = r\"D:\\Compiled\"\n",
    "\n",
    "classes = ('Background', 'Palm_Tree')\n",
    "\n",
    "palette = [[0, 0, 0], [0, 137, 37]]\n",
    "\n",
    "\n",
    "config_file = r\"C:\\Users\\0581979618\\mmsegmentation\\configs\\segformer\\segformer_mit-b2_512x512_160k_ade20k.py\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "@DATASETS.register_module()\n",
    "\n",
    "class Palm_trees(CustomDataset):\n",
    "    \"\"\"Custom dataset for semantic segmentation.\n",
    "\n",
    "    An example of file structure is as followed.\n",
    "\n",
    "    .. code-block:: none\n",
    "\n",
    "        ├── data\n",
    "        │   ├── my_dataset\n",
    "        │   │   ├── img_dir\n",
    "        │   │   │   ├── train\n",
    "        │   │   │   │   ├── xxx{img_suffix}\n",
    "        │   │   │   │   ├── yyy{img_suffix}\n",
    "        │   │   │   │   ├── zzz{img_suffix}\n",
    "        │   │   │   ├── val\n",
    "        │   │   ├── ann_dir\n",
    "        │   │   │   ├── train\n",
    "        │   │   │   │   ├── xxx{seg_map_suffix}\n",
    "        │   │   │   │   ├── yyy{seg_map_suffix}\n",
    "        │   │   │   │   ├── zzz{seg_map_suffix}\n",
    "        │   │   │   ├── val\n",
    "\n",
    "    The img/gt_semantic_seg pair of CustomDataset should be of the same\n",
    "    except suffix. A valid img/gt_semantic_seg filename pair should be like\n",
    "    ``xxx{img_suffix}`` and ``xxx{seg_map_suffix}`` (extension is also included\n",
    "    in the suffix). If split is given, then ``xxx`` is specified in txt file.\n",
    "    Otherwise, all files in ``img_dir/``and ``ann_dir`` will be loaded.\n",
    "    Please refer to ``docs/tutorials/new_dataset.md`` for more details.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        pipeline (list[dict]): Processing pipeline\n",
    "        img_dir (str): Path to image directory\n",
    "        img_suffix (str): Suffix of images. Default: '.png'\n",
    "        ann_dir (str, optional): Path to annotation directory. Default: None\n",
    "        seg_map_suffix (str): Suffix of segmentation maps. Default: '.png'\n",
    "        split (str, optional): Split txt file. If split is specified, only\n",
    "            file with suffix in the splits will be loaded. Otherwise, all\n",
    "            images in img_dir/ann_dir will be loaded. Default: None\n",
    "        data_root (str, optional): Data root for img_dir/ann_dir. Default:\n",
    "            None.\n",
    "        test_mode (bool): If test_mode=True, gt wouldn't be loaded.\n",
    "        ignore_index (int): The label index to be ignored. Default: 255\n",
    "        reduce_zero_label (bool): Whether to mark label zero as ignored.\n",
    "            Default: False\n",
    "    \"\"\"\n",
    "\n",
    "    CLASSES = ('BG', 'Tree')\n",
    "\n",
    "    PALETTE = [[0, 0, 0], [0, 137, 37]]\n",
    "    \n",
    "\n",
    "def __init__(self,\n",
    "             pipeline,\n",
    "             img_dir,\n",
    "             img_suffix='.png',\n",
    "             ann_dir=None,\n",
    "             seg_map_suffix='.png',\n",
    "             split=None,\n",
    "             data_root=None,\n",
    "             test_mode=False,\n",
    "             ignore_index=255,\n",
    "             reduce_zero_label=False):\n",
    "    self.pipeline = Compose(pipeline)\n",
    "    self.img_dir = img_dir\n",
    "    self.img_suffix = img_suffix\n",
    "    self.ann_dir = ann_dir\n",
    "    self.seg_map_suffix = seg_map_suffix\n",
    "    self.split = split\n",
    "    self.data_root = data_root\n",
    "    self.test_mode = test_mode\n",
    "    self.ignore_index = ignore_index\n",
    "    self.reduce_zero_label = reduce_zero_label\n",
    "\n",
    "    # join paths if data_root is specified\n",
    "    # self.img_dir = osp.join(self.data_root, self.img_dir)\n",
    "    # self.ann_dir = osp.join(self.data_root, self.ann_dir)\n",
    "    if self.data_root is not None:\n",
    "        if not osp.isabs(self.img_dir):\n",
    "            self.img_dir = osp.join(self.data_root, self.img_dir)\n",
    "            print(self.img_dir)\n",
    "        if not (self.ann_dir is None or osp.isabs(self.ann_dir)):\n",
    "            self.ann_dir = osp.join(self.data_root, self.ann_dir)\n",
    "        if not (self.split is None or osp.isabs(self.split)):\n",
    "            self.split = osp.join(self.data_root, self.split)\n",
    "    # print(self.img_dir,'***************************')\n",
    "    # load annotations\n",
    "    self.img_infos = self.load_annotations(self.img_dir, self.img_suffix,\n",
    "                                           self.ann_dir,\n",
    "                                           self.seg_map_suffix, self.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wwnj9tRzqX_A"
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "\n",
    "config_file = r\"C:\\Users\\0581979618\\mmsegmentation\\configs\\segformer\\segformer_mit-b2_512x512_160k_ade20k.py\"\n",
    "checkpoint_file = \"/home/mbgibril/mmsegmentation/checkpoints/dpt_vit-b16_512x512_160k_ade20k-db31cf52.pth\"\n",
    "cfg = Config.fromfile(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUVtmn3Iq3WA"
   },
   "source": [
    "### Create a config file\n",
    "In the next step, we need to modify the config for the training. To accelerate the process, we finetune the model from trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyKnYC1Z7iCV",
    "outputId": "ac11dedc-1e7a-4426-9f90-6ceb30580566"
   },
   "outputs": [],
   "source": [
    "from mmseg.apis import set_random_seed\n",
    "\n",
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "#cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "#cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 2\n",
    "#cfg.model.auxiliary_head.num_classes = 2\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'Palm_trees'\n",
    "cfg.data_root = data_root\n",
    "\n",
    "#cfg.optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "cfg.optimizer = dict(type='Adam', lr=1e-3, weight_decay=0.0001,\n",
    "                     paramwise_cfg = dict(\n",
    "                        custom_keys={\n",
    "                            'head': dict(lr_mult=10.)\n",
    "                        }\n",
    "                        ))\n",
    "\n",
    "cfg.data.samples_per_gpu =2\n",
    "cfg.data.workers_per_gpu =2\n",
    "#cfg.img_norm_cfg = dict(\n",
    "    #mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "cfg.crop_size = (512, 512)\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(512, 512), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(512, 512),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.img_dir = 'img_dir/train'\n",
    "cfg.data.train.ann_dir = 'ann_dir/train'\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.img_dir = 'img_dir/val'\n",
    "cfg.data.val.ann_dir = 'ann_dir/val'\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root \n",
    "cfg.data.test.img_dir = 'img_dir/test'\n",
    "cfg.data.test.ann_dir = 'ann_dir/test'\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "\n",
    "\n",
    "cfg.load_from = checkpoint_file\n",
    "#cfg.resume_from = \"\"\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = \"Output\"\n",
    "\n",
    "# runtime settings\n",
    "cfg.runner = dict(type='IterBasedRunner', max_iters=20000)\n",
    "#evaluation = dict(interval=2000, metric='mIoU', pre_eval=True)\n",
    "\n",
    "\n",
    "cfg.runner.max_iters = 100000\n",
    "cfg.log_config.interval = 10\n",
    "cfg.evaluation.interval = 2000\n",
    "cfg.evaluation.metric = 'mIoU'\n",
    "cfg.checkpoint_config.interval = 2000\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# We can also use tensorboard to log the training process\n",
    "cfg.log_config.hooks = [\n",
    "    dict(type='TextLoggerHook'),\n",
    "    dict(type='TensorboardLoggerHook')]\n",
    "\n",
    "\n",
    "meta = dict()\n",
    "meta['config'] = cfg.pretty_text\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Segmentor and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "import random\n",
    "import time\n",
    "# Use your trained model\n",
    "\n",
    "config_file = \"segformer_mit-b2_512x512_160k_ade20k.py\"\n",
    "checkpoint_file='iter_46000.pth'\n",
    "\n",
    "\n",
    "Validation_image_path = 'image'\n",
    "\n",
    "cfg = Config.fromfile(config_file)\n",
    "\n",
    "model = init_segmentor(config_file, checkpoint_file, device='cuda:0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random test image and visualize it with model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images_list = os.listdir(Validation_image_path)\n",
    "rand_num = random.randint(0, len(images_list))\n",
    "Path= os.path.join(Validation_image_path, images_list[rand_num])\n",
    "img = mmcv.imread(Path)\n",
    "\n",
    "start = time.time()\n",
    "result = inference_segmentor(model, img)\n",
    "print('[INFO]timecost: ', time.time() - start)\n",
    " \n",
    "\n",
    "#palette=[[0, 0, 0], [10, 255, 10]] \n",
    "palette=[[0, 0, 0], [0, 176, 80]]\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "# visualize the results \n",
    "show_result_pyplot(model, img, result, palette,opacity=0.55)\n",
    "# or save the visualization results to image files\n",
    "#model.show_result(img, result, out_file='result1111.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "config_file = \"segformer_mit-b2_512x512_160k_ade20k.py\"\n",
    "checkpoint_file='iter_46000.pth'\n",
    "\n",
    "output_dir= \"Segformer B2\"\n",
    "\n",
    "Images= 'Data'\n",
    "\n",
    "images = glob.glob(Images+'/*.jpg')\n",
    "\n",
    "model.cfg = cfg\n",
    "\n",
    "\n",
    "for image in tqdm(images):\n",
    "    img = mmcv.imread(image)\n",
    "    result = inference_segmentor(model, img)\n",
    "    palette=[[0, 0, 0], [32, 163, 32]]\n",
    "    # visualize the results \n",
    "    out=model.show_result(img, result,palette,opacity=0.55)\n",
    "    cv2.imwrite(os.path.join(output_dir, os.path.basename(image)),out) #save the result in the same testing folder\n",
    "    #cv2.imwrite(os.path.join(output_dir, os.path.basename(image),(result[0]*255).astype(np.uint8)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of MMSegmentation Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
